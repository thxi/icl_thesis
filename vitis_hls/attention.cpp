#define d 16  // input embedding size

// query key and attention embedding sizes
#define dQ 24
#define dK 24
#define dV 28

// raw numpy attention calculation
// https://github.com/p208p2002/Self-Attention-cacultate-with-numpy

// attention from scratch:
// https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html

// we want to multiply a matrix of size dxN by a vector of size N
